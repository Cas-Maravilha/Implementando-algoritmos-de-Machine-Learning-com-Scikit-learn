# -*- coding: utf-8 -*-
"""
Compara√ß√£o de Algoritmos de Classifica√ß√£o
=========================================

Este script implementa e compara diferentes algoritmos de classifica√ß√£o
seguindo os passos especificados:

1. Separa√ß√£o dos dados (70% treino, 30% teste)
2. Implementa√ß√£o de 5 algoritmos diferentes
3. Treinamento dos modelos
4. Avalia√ß√£o com m√∫ltiplas m√©tricas
5. Compara√ß√£o de desempenho

Algoritmos implementados:
- K-Nearest Neighbors (KNN)
- Support Vector Machine (SVM)
- Random Forest
- Naive Bayes
- Logistic Regression

Autor: Assistente IA
Data: 2024
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
import warnings
import time

# Configura√ß√µes
warnings.filterwarnings('ignore')
plt.style.use('seaborn-v0_8')
sns.set_palette('husl')
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# Configura√ß√µes do pandas
pd.set_option('display.max_columns', None)
pd.set_option('display.float_format', lambda x: '%.3f' % x)

class ComparacaoAlgoritmos:
    """
    Classe para comparar diferentes algoritmos de classifica√ß√£o
    """
    
    def __init__(self, random_state=42):
        self.random_state = random_state
        self.df = None
        self.X = None
        self.y = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        self.y_test = None
        self.scaler = None
        self.models = {}
        self.results = {}
        self.class_names = ['Kama', 'Rosa', 'Canadian']
        
        # Definir nomes das features
        self.feature_names = [
            'area', 'perimetro', 'compacidade', 'comprimento_kernel',
            'largura_kernel', 'coef_assimetria', 'comprimento_sulco'
        ]
    
    def carregar_dados(self):
        """Carrega o dataset de sementes"""
        try:
            print("üìä Carregando dataset...")
            
            colunas = self.feature_names + ['classe']
            url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'
            self.df = pd.read_csv(url, names=colunas, sep=r'\s+')
            
            print(f"‚úÖ Dataset carregado com {self.df.shape[0]} amostras e {self.df.shape[1]} atributos")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {str(e)}")
            return False
    
    def explorar_dados(self):
        """Explora√ß√£o b√°sica dos dados"""
        print("\n" + "="*60)
        print("EXPLORA√á√ÉO DOS DADOS")
        print("="*60)
        
        print(f"\nüìä Shape do dataset: {self.df.shape}")
        print(f"üìã Colunas: {list(self.df.columns)}")
        
        print("\nüìà Primeiras 5 linhas:")
        print(self.df.head())
        
        print("\nüìä Informa√ß√µes do dataset:")
        print(self.df.info())
        
        print("\nüìà Estat√≠sticas descritivas:")
        print(self.df.describe())
        
        print("\nüîç Valores nulos por coluna:")
        print(self.df.isnull().sum())
        
        # Distribui√ß√£o das classes
        print("\nüéØ Distribui√ß√£o das classes:")
        class_counts = self.df['classe'].value_counts().sort_index()
        for i, count in class_counts.items():
            print(f"  Classe {i} ({self.class_names[i-1]}): {count} amostras ({count/len(self.df)*100:.1f}%)")
        
        # Visualizar distribui√ß√£o das classes
        plt.figure(figsize=(10, 6))
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']
        plt.pie(class_counts.values, labels=[f'{self.class_names[i-1]}\n({count})' 
                                           for i, count in class_counts.items()], 
               colors=colors, autopct='%1.1f%%', startangle=90)
        plt.title('Distribui√ß√£o das Classes', fontsize=14, fontweight='bold')
        plt.show()
    
    def preparar_dados(self):
        """Prepara os dados para modelagem"""
        print("\n" + "="*60)
        print("PREPARA√á√ÉO DOS DADOS")
        print("="*60)
        
        # Separando features e target
        self.X = self.df.drop('classe', axis=1)
        self.y = self.df['classe']
        
        print(f"üìä Features (X): {self.X.shape}")
        print(f"üéØ Target (y): {self.y.shape}")
        
        # SEPARA√á√ÉO DOS DADOS: 70% treino, 30% teste
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
            self.X, self.y, test_size=0.3, random_state=self.random_state, stratify=self.y
        )
        
        print(f"\nüìà Conjunto de treino: {self.X_train.shape[0]} amostras (70%)")
        print(f"üìä Conjunto de teste: {self.X_test.shape[0]} amostras (30%)")
        
        # Verificar distribui√ß√£o das classes nos conjuntos
        print(f"\nüéØ Distribui√ß√£o das classes no treino:")
        train_counts = self.y_train.value_counts().sort_index()
        for i, count in train_counts.items():
            print(f"  Classe {i} ({self.class_names[i-1]}): {count} amostras")
        
        print(f"\nüéØ Distribui√ß√£o das classes no teste:")
        test_counts = self.y_test.value_counts().sort_index()
        for i, count in test_counts.items():
            print(f"  Classe {i} ({self.class_names[i-1]}): {count} amostras")
        
        # Normaliza√ß√£o dos dados
        print(f"\nüîß Normalizando dados...")
        self.scaler = StandardScaler()
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_test_scaled = self.scaler.transform(self.X_test)
        
        print("‚úÖ Dados normalizados com sucesso!")
    
    def definir_algoritmos(self):
        """Define os algoritmos de classifica√ß√£o"""
        print("\n" + "="*60)
        print("DEFININDO ALGORITMOS DE CLASSIFICA√á√ÉO")
        print("="*60)
        
        # 1. K-Nearest Neighbors (KNN)
        knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')
        
        # 2. Support Vector Machine (SVM)
        svm = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=self.random_state)
        
        # 3. Random Forest
        rf = RandomForestClassifier(n_estimators=100, random_state=self.random_state)
        
        # 4. Naive Bayes
        nb = GaussianNB()
        
        # 5. Logistic Regression
        lr = LogisticRegression(random_state=self.random_state, max_iter=1000)
        
        self.models = {
            'K-Nearest Neighbors (KNN)': knn,
            'Support Vector Machine (SVM)': svm,
            'Random Forest': rf,
            'Naive Bayes': nb,
            'Logistic Regression': lr
        }
        
        print("‚úÖ Algoritmos definidos:")
        for name in self.models.keys():
            print(f"  - {name}")
    
    def treinar_modelos(self):
        """Treina todos os modelos"""
        print("\n" + "="*60)
        print("TREINAMENTO DOS MODELOS")
        print("="*60)
        
        for name, model in self.models.items():
            print(f"\nüîß Treinando {name}...")
            start_time = time.time()
            
            # Alguns modelos precisam de dados normalizados, outros n√£o
            if name in ['K-Nearest Neighbors (KNN)', 'Support Vector Machine (SVM)', 'Logistic Regression']:
                model.fit(self.X_train_scaled, self.y_train)
            else:
                model.fit(self.X_train, self.y_train)
            
            training_time = time.time() - start_time
            print(f"  ‚è±Ô∏è Tempo de treinamento: {training_time:.3f} segundos")
            print(f"  ‚úÖ Modelo treinado com sucesso!")
    
    def avaliar_modelos(self):
        """Avalia todos os modelos no conjunto de teste"""
        print("\n" + "="*60)
        print("AVALIA√á√ÉO DOS MODELOS")
        print("="*60)
        
        for name, model in self.models.items():
            print(f"\nüìä Avaliando {name}...")
            
            # Fazer predi√ß√µes
            if name in ['K-Nearest Neighbors (KNN)', 'Support Vector Machine (SVM)', 'Logistic Regression']:
                y_pred = model.predict(self.X_test_scaled)
            else:
                y_pred = model.predict(self.X_test)
            
            # Calcular m√©tricas
            accuracy = accuracy_score(self.y_test, y_pred)
            precision = precision_score(self.y_test, y_pred, average='weighted')
            recall = recall_score(self.y_test, y_pred, average='weighted')
            f1 = f1_score(self.y_test, y_pred, average='weighted')
            
            # Armazenar resultados
            self.results[name] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_score': f1,
                'y_pred': y_pred
            }
            
            # Imprimir resultados
            print(f"  üìà Acur√°cia: {accuracy:.3f}")
            print(f"  üìä Precis√£o: {precision:.3f}")
            print(f"  üîÑ Recall: {recall:.3f}")
            print(f"  ‚öñÔ∏è F1-Score: {f1:.3f}")
    
    def criar_matrizes_confusao(self):
        """Cria matrizes de confus√£o para todos os modelos"""
        print("\n" + "="*60)
        print("MATRIZES DE CONFUS√ÉO")
        print("="*60)
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.ravel()
        
        for i, (name, model) in enumerate(self.models.items()):
            y_pred = self.results[name]['y_pred']
            cm = confusion_matrix(self.y_test, y_pred)
            
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=self.class_names, yticklabels=self.class_names, ax=axes[i])
            axes[i].set_title(f'Matriz de Confus√£o - {name}', fontweight='bold')
            axes[i].set_xlabel('Predi√ß√£o')
            axes[i].set_ylabel('Real')
        
        # Remover subplot extra
        axes[-1].remove()
        
        plt.tight_layout()
        plt.show()
    
    def comparar_desempenho(self):
        """Compara o desempenho dos diferentes algoritmos"""
        print("\n" + "="*60)
        print("COMPARA√á√ÉO DE DESEMPENHO")
        print("="*60)
        
        # Criar DataFrame com resultados
        results_df = pd.DataFrame(self.results).T
        print("\nüìä Tabela de Resultados:")
        print(results_df.round(3))
        
        # Visualizar compara√ß√£o
        metrics = ['accuracy', 'precision', 'recall', 'f1_score']
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.ravel()
        
        for i, metric in enumerate(metrics):
            values = [self.results[name][metric] for name in self.models.keys()]
            axes[i].bar(self.models.keys(), values, color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'])
            axes[i].set_title(f'{metric.replace("_", " ").title()}', fontweight='bold')
            axes[i].set_ylabel('Score')
            axes[i].tick_params(axis='x', rotation=45)
            
            # Adicionar valores nas barras
            for j, v in enumerate(values):
                axes[i].text(j, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.show()
        
        # Identificar melhor modelo
        best_model = max(self.results.keys(), key=lambda x: self.results[x]['f1_score'])
        print(f"\nüèÜ MELHOR MODELO: {best_model}")
        print(f"üìà F1-Score: {self.results[best_model]['f1_score']:.3f}")
        print(f"üéØ Acur√°cia: {self.results[best_model]['accuracy']:.3f}")
    
    def relatorios_detalhados(self):
        """Gera relat√≥rios detalhados de classifica√ß√£o"""
        print("\n" + "="*60)
        print("RELAT√ìRIOS DETALHADOS DE CLASSIFICA√á√ÉO")
        print("="*60)
        
        for name, model in self.models.items():
            y_pred = self.results[name]['y_pred']
            
            print(f"\nüìã Relat√≥rio de Classifica√ß√£o - {name}")
            print("=" * 50)
            print(classification_report(self.y_test, y_pred, target_names=self.class_names))
    
    def analise_erros(self):
        """Analisa os erros de classifica√ß√£o"""
        print("\n" + "="*60)
        print("AN√ÅLISE DE ERROS DE CLASSIFICA√á√ÉO")
        print("="*60)
        
        # Identificar amostras mal classificadas
        for name, model in self.models.items():
            y_pred = self.results[name]['y_pred']
            errors = self.y_test != y_pred
            
            if errors.sum() > 0:
                print(f"\n‚ùå {name}: {errors.sum()} erros de classifica√ß√£o")
                print("Amostras mal classificadas:")
                
                error_indices = self.X_test.index[errors]
                for idx in error_indices[:5]:  # Mostrar apenas os primeiros 5 erros
                    true_class = self.y_test.loc[idx]
                    pred_class = y_pred[errors][list(error_indices).index(idx)]
                    print(f"  Amostra {idx}: Real={true_class}({self.class_names[true_class-1]}) -> Pred={pred_class}({self.class_names[pred_class-1]})")
            else:
                print(f"\n‚úÖ {name}: 0 erros de classifica√ß√£o!")
    
    def executar_analise_completa(self):
        """Executa a an√°lise completa de compara√ß√£o de algoritmos"""
        print("=" * 60)
        print("COMPARA√á√ÉO DE ALGORITMOS DE CLASSIFICA√á√ÉO")
        print("=" * 60)
        
        # 1. Carregar dados
        if not self.carregar_dados():
            return False
        
        # 2. Explorar dados
        self.explorar_dados()
        
        # 3. Preparar dados (70% treino, 30% teste)
        self.preparar_dados()
        
        # 4. Definir algoritmos
        self.definir_algoritmos()
        
        # 5. Treinar modelos
        self.treinar_modelos()
        
        # 6. Avaliar modelos
        self.avaliar_modelos()
        
        # 7. Criar matrizes de confus√£o
        self.criar_matrizes_confusao()
        
        # 8. Comparar desempenho
        self.comparar_desempenho()
        
        # 9. Relat√≥rios detalhados
        self.relatorios_detalhados()
        
        # 10. An√°lise de erros
        self.analise_erros()
        
        print(f"\n{'='*60}")
        print("AN√ÅLISE CONCLU√çDA COM SUCESSO!")
        print(f"{'='*60}")
        print("‚úÖ Dados carregados e explorados")
        print("‚úÖ Dados separados (70% treino, 30% teste)")
        print("‚úÖ 5 algoritmos implementados e treinados")
        print("‚úÖ Modelos avaliados com m√∫ltiplas m√©tricas")
        print("‚úÖ Matrizes de confus√£o geradas")
        print("‚úÖ Compara√ß√£o de desempenho realizada")
        print("‚úÖ Relat√≥rios detalhados criados")
        print("‚úÖ An√°lise de erros conclu√≠da")
        
        return True

def main():
    """Fun√ß√£o principal"""
    try:
        # Criar inst√¢ncia da compara√ß√£o
        comparacao = ComparacaoAlgoritmos(random_state=42)
        
        # Executar an√°lise completa
        success = comparacao.executar_analise_completa()
        
        if success:
            print("\nüéâ Compara√ß√£o de algoritmos conclu√≠da com sucesso!")
        else:
            print("\n‚ùå Erro na execu√ß√£o da an√°lise.")
            
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è An√°lise interrompida pelo usu√°rio.")
    except Exception as e:
        print(f"\n‚ùå Erro inesperado: {str(e)}")

if __name__ == "__main__":
    main() 